{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# https://arxiv.org/abs/1905.11946"
      ],
      "metadata": {
        "id": "wYIf5yMpKXLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFp0cpbQDQTx"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxkX8_Q-DR5e"
      },
      "outputs": [],
      "source": [
        "def relu_fn(x):\n",
        "    \"\"\" Swish activation function \"\"\"\n",
        "    return x * torch.sigmoid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxUQ_7PFDR8J"
      },
      "outputs": [],
      "source": [
        "class Conv2dSamePadding(nn.Conv2d):\n",
        "    \"\"\" 2D Convolutions like TensorFlow \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1, groups=1, bias=True):\n",
        "        super().__init__(in_channels, out_channels, kernel_size, stride, 0, dilation, groups, bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ih, iw = x.size()[-2:]\n",
        "        kh, kw = self.weight.size()[-2:]\n",
        "        sh, sw = self.stride\n",
        "        oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)\n",
        "        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n",
        "        pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\n",
        "        if pad_h > 0 or pad_w > 0:\n",
        "            x = F.pad(x, [pad_w//2, pad_w - pad_w//2, pad_h//2, pad_h - pad_h//2])\n",
        "        return F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4eNnv0xDR_y"
      },
      "outputs": [],
      "source": [
        "def drop_connect(inputs, p, training):\n",
        "    \"\"\" Drop connect. \"\"\"\n",
        "    if not training: return inputs\n",
        "    batch_size = inputs.shape[0]\n",
        "    keep_prob = 1 - p\n",
        "    random_tensor = keep_prob\n",
        "    random_tensor += torch.rand([batch_size, 1, 1, 1], dtype=inputs.dtype)  # uniform [0,1)\n",
        "    binary_tensor = torch.floor(random_tensor)\n",
        "    output = inputs / keep_prob * binary_tensor\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCghS3fMDSBW"
      },
      "outputs": [],
      "source": [
        "class MBConvBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Mobile Inverted Residual Bottleneck Block\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, kernel_size, stride, expand_ratio, input_filters, output_filters, se_ratio, drop_n_add):\n",
        "        super().__init__()\n",
        "        \n",
        "        self._bn_mom = 0.1\n",
        "        self._bn_eps = 1e-03\n",
        "        self.has_se = (se_ratio is not None) and (0 < se_ratio <= 1)\n",
        "        self.expand_ratio = expand_ratio\n",
        "        self.drop_n_add = drop_n_add\n",
        "\n",
        "        # Filter Expansion phase\n",
        "        inp = input_filters  # number of input channels\n",
        "        oup = input_filters * expand_ratio  # number of output channels\n",
        "        if expand_ratio != 1: # add it except at first block \n",
        "            self._expand_conv = Conv2dSamePadding(in_channels=inp, out_channels=oup, kernel_size=1, bias=False)\n",
        "            self._bn0 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
        "\n",
        "        # Depthwise convolution phase\n",
        "        k = kernel_size\n",
        "        s = stride\n",
        "        self._depthwise_conv = Conv2dSamePadding(\n",
        "            in_channels=oup, out_channels=oup, groups=oup,  # groups makes it depthwise(conv filter by filter)\n",
        "            kernel_size=k, stride=s, bias=False)\n",
        "        self._bn1 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
        "\n",
        "        # Squeeze and Excitation layer, if desired\n",
        "        if self.has_se:\n",
        "            num_squeezed_channels = max(1,int(input_filters * se_ratio))  # input channel * 0.25 ex) block2 => 16 * 0.25 = 4\n",
        "            self._se_reduce = Conv2dSamePadding(in_channels=oup, out_channels=num_squeezed_channels, kernel_size=1)\n",
        "            self._se_expand = Conv2dSamePadding(in_channels=num_squeezed_channels, out_channels=oup, kernel_size=1)\n",
        "\n",
        "        # Output phase\n",
        "        final_oup = output_filters\n",
        "        self._project_conv = Conv2dSamePadding(in_channels=oup, out_channels=final_oup, kernel_size=1, bias=False)\n",
        "        self._bn2 = nn.BatchNorm2d(num_features=final_oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
        "\n",
        "    def forward(self, inputs, drop_connect_rate=0.2):\n",
        "\n",
        "        # Expansion and Depthwise Convolution\n",
        "        x = inputs\n",
        "        if self.expand_ratio != 1:\n",
        "            x = relu_fn(self._bn0(self._expand_conv(inputs)))\n",
        "        x = relu_fn(self._bn1(self._depthwise_conv(x)))\n",
        "\n",
        "        # Squeeze and Excitation\n",
        "        if self.has_se:\n",
        "            x_squeezed = F.adaptive_avg_pool2d(x, 1)\n",
        "            x_squeezed = self._se_expand(relu_fn(self._se_reduce(x_squeezed)))\n",
        "            x = torch.sigmoid(x_squeezed) * x\n",
        "            \n",
        "        # Output phase\n",
        "        x = self._bn2(self._project_conv(x))\n",
        "\n",
        "        # Skip connection and drop connect\n",
        "        if self.drop_n_add == True:\n",
        "            if drop_connect_rate:\n",
        "                x = drop_connect(x, p=drop_connect_rate, training=self.training)\n",
        "            x = x + inputs  # skip connection\n",
        "        return x      \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3MdCbE1DSDG"
      },
      "outputs": [],
      "source": [
        "class EfficientNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Batch norm parameters\n",
        "        bn_mom = 0.1\n",
        "        bn_eps = 1e-03\n",
        "\n",
        "        # stem\n",
        "        in_channels = 3\n",
        "        out_channels = 32\n",
        "        self._conv_stem = Conv2dSamePadding(in_channels, out_channels, kernel_size=3, stride=2, bias=False)\n",
        "        self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
        "\n",
        "        # Build blocks\n",
        "        self._blocks = nn.ModuleList([]) # list 형태로 model 구성할 때\n",
        "        # stage2 r1_k3_s11_e1_i32_o16_se0.25\n",
        "        self._blocks.append(MBConvBlock(kernel_size=3, stride=1, expand_ratio=1, input_filters=32, output_filters=16, se_ratio=0.25, drop_n_add=False))\n",
        "        # stage3 r2_k3_s22_e6_i16_o24_se0.25\n",
        "        self._blocks.append(MBConvBlock(3, 2, 6, 16, 24, 0.25, False))\n",
        "        self._blocks.append(MBConvBlock(3, 1, 6, 24, 24, 0.25, True))\n",
        "        # stage4 r2_k5_s22_e6_i24_o40_se0.25\n",
        "        self._blocks.append(MBConvBlock(5, 2, 6, 24, 40, 0.25, False))\n",
        "        self._blocks.append(MBConvBlock(5, 1, 6, 40, 40, 0.25, True))\n",
        "        # stage5 r3_k3_s22_e6_i40_o80_se0.25\n",
        "        self._blocks.append(MBConvBlock(3, 2, 6, 40, 80, 0.25, False))\n",
        "        self._blocks.append(MBConvBlock(3, 1, 6, 80, 80, 0.25, True))\n",
        "        self._blocks.append(MBConvBlock(3, 1, 6, 80, 80, 0.25, True))\n",
        "        # stage6 r3_k5_s11_e6_i80_o112_se0.25\n",
        "        self._blocks.append(MBConvBlock(5, 1, 6, 80,  112, 0.25, False))\n",
        "        self._blocks.append(MBConvBlock(5, 1, 6, 112, 112, 0.25, True))\n",
        "        self._blocks.append(MBConvBlock(5, 1, 6, 112, 112, 0.25, True))\n",
        "        # stage7 r4_k5_s22_e6_i112_o192_se0.25\n",
        "        self._blocks.append(MBConvBlock(5, 2, 6, 112, 192, 0.25, False))\n",
        "        self._blocks.append(MBConvBlock(5, 1, 6, 192, 192, 0.25, True))\n",
        "        self._blocks.append(MBConvBlock(5, 1, 6, 192, 192, 0.25, True))\n",
        "        self._blocks.append(MBConvBlock(5, 1, 6, 192, 192, 0.25, True))\n",
        "        # stage8 r1_k3_s11_e6_i192_o320_se0.25\n",
        "        self._blocks.append(MBConvBlock(3, 1, 6, 192, 320, 0.25, False))\n",
        "\n",
        "        # Head \n",
        "        in_channels = 320\n",
        "        out_channels = 1280\n",
        "        self._conv_head = Conv2dSamePadding(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self._bn1 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
        "\n",
        "        # Final linear layer\n",
        "        self._dropout = 0.2\n",
        "        self._num_classes = 10\n",
        "        self._fc = nn.Linear(out_channels, self._num_classes)\n",
        "\n",
        "    def extract_features(self, inputs):\n",
        "        \"\"\" Returns output of the final convolution layer \"\"\"\n",
        "\n",
        "        # Stem\n",
        "        x = relu_fn(self._bn0(self._conv_stem(inputs)))\n",
        "\n",
        "        # Blocks\n",
        "        for idx, block in enumerate(self._blocks):          \n",
        "            x = block(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\" Calls extract_features to extract features, applies final linear layer, and returns logits. \"\"\"\n",
        "\n",
        "        # Convolution layers\n",
        "        x = self.extract_features(inputs)\n",
        "\n",
        "        # Head\n",
        "        x = relu_fn(self._bn1(self._conv_head(x)))\n",
        "        x = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
        "        if self._dropout:\n",
        "            x = F.dropout(x, p=self._dropout, training=self.training)\n",
        "        x = self._fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9ifGBdfDlTt",
        "outputId": "cc56830b-e56a-4eec-b781-1df9b041de2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            " Conv2dSamePadding-1         [-1, 32, 112, 112]             864\n",
            "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
            " Conv2dSamePadding-3         [-1, 32, 112, 112]             288\n",
            "       BatchNorm2d-4         [-1, 32, 112, 112]              64\n",
            " Conv2dSamePadding-5              [-1, 8, 1, 1]             264\n",
            " Conv2dSamePadding-6             [-1, 32, 1, 1]             288\n",
            " Conv2dSamePadding-7         [-1, 16, 112, 112]             512\n",
            "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
            "       MBConvBlock-9         [-1, 16, 112, 112]               0\n",
            "Conv2dSamePadding-10         [-1, 96, 112, 112]           1,536\n",
            "      BatchNorm2d-11         [-1, 96, 112, 112]             192\n",
            "Conv2dSamePadding-12           [-1, 96, 56, 56]             864\n",
            "      BatchNorm2d-13           [-1, 96, 56, 56]             192\n",
            "Conv2dSamePadding-14              [-1, 4, 1, 1]             388\n",
            "Conv2dSamePadding-15             [-1, 96, 1, 1]             480\n",
            "Conv2dSamePadding-16           [-1, 24, 56, 56]           2,304\n",
            "      BatchNorm2d-17           [-1, 24, 56, 56]              48\n",
            "      MBConvBlock-18           [-1, 24, 56, 56]               0\n",
            "Conv2dSamePadding-19          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-20          [-1, 144, 56, 56]             288\n",
            "Conv2dSamePadding-21          [-1, 144, 56, 56]           1,296\n",
            "      BatchNorm2d-22          [-1, 144, 56, 56]             288\n",
            "Conv2dSamePadding-23              [-1, 6, 1, 1]             870\n",
            "Conv2dSamePadding-24            [-1, 144, 1, 1]           1,008\n",
            "Conv2dSamePadding-25           [-1, 24, 56, 56]           3,456\n",
            "      BatchNorm2d-26           [-1, 24, 56, 56]              48\n",
            "      MBConvBlock-27           [-1, 24, 56, 56]               0\n",
            "Conv2dSamePadding-28          [-1, 144, 56, 56]           3,456\n",
            "      BatchNorm2d-29          [-1, 144, 56, 56]             288\n",
            "Conv2dSamePadding-30          [-1, 144, 28, 28]           3,600\n",
            "      BatchNorm2d-31          [-1, 144, 28, 28]             288\n",
            "Conv2dSamePadding-32              [-1, 6, 1, 1]             870\n",
            "Conv2dSamePadding-33            [-1, 144, 1, 1]           1,008\n",
            "Conv2dSamePadding-34           [-1, 40, 28, 28]           5,760\n",
            "      BatchNorm2d-35           [-1, 40, 28, 28]              80\n",
            "      MBConvBlock-36           [-1, 40, 28, 28]               0\n",
            "Conv2dSamePadding-37          [-1, 240, 28, 28]           9,600\n",
            "      BatchNorm2d-38          [-1, 240, 28, 28]             480\n",
            "Conv2dSamePadding-39          [-1, 240, 28, 28]           6,000\n",
            "      BatchNorm2d-40          [-1, 240, 28, 28]             480\n",
            "Conv2dSamePadding-41             [-1, 10, 1, 1]           2,410\n",
            "Conv2dSamePadding-42            [-1, 240, 1, 1]           2,640\n",
            "Conv2dSamePadding-43           [-1, 40, 28, 28]           9,600\n",
            "      BatchNorm2d-44           [-1, 40, 28, 28]              80\n",
            "      MBConvBlock-45           [-1, 40, 28, 28]               0\n",
            "Conv2dSamePadding-46          [-1, 240, 28, 28]           9,600\n",
            "      BatchNorm2d-47          [-1, 240, 28, 28]             480\n",
            "Conv2dSamePadding-48          [-1, 240, 14, 14]           2,160\n",
            "      BatchNorm2d-49          [-1, 240, 14, 14]             480\n",
            "Conv2dSamePadding-50             [-1, 10, 1, 1]           2,410\n",
            "Conv2dSamePadding-51            [-1, 240, 1, 1]           2,640\n",
            "Conv2dSamePadding-52           [-1, 80, 14, 14]          19,200\n",
            "      BatchNorm2d-53           [-1, 80, 14, 14]             160\n",
            "      MBConvBlock-54           [-1, 80, 14, 14]               0\n",
            "Conv2dSamePadding-55          [-1, 480, 14, 14]          38,400\n",
            "      BatchNorm2d-56          [-1, 480, 14, 14]             960\n",
            "Conv2dSamePadding-57          [-1, 480, 14, 14]           4,320\n",
            "      BatchNorm2d-58          [-1, 480, 14, 14]             960\n",
            "Conv2dSamePadding-59             [-1, 20, 1, 1]           9,620\n",
            "Conv2dSamePadding-60            [-1, 480, 1, 1]          10,080\n",
            "Conv2dSamePadding-61           [-1, 80, 14, 14]          38,400\n",
            "      BatchNorm2d-62           [-1, 80, 14, 14]             160\n",
            "      MBConvBlock-63           [-1, 80, 14, 14]               0\n",
            "Conv2dSamePadding-64          [-1, 480, 14, 14]          38,400\n",
            "      BatchNorm2d-65          [-1, 480, 14, 14]             960\n",
            "Conv2dSamePadding-66          [-1, 480, 14, 14]           4,320\n",
            "      BatchNorm2d-67          [-1, 480, 14, 14]             960\n",
            "Conv2dSamePadding-68             [-1, 20, 1, 1]           9,620\n",
            "Conv2dSamePadding-69            [-1, 480, 1, 1]          10,080\n",
            "Conv2dSamePadding-70           [-1, 80, 14, 14]          38,400\n",
            "      BatchNorm2d-71           [-1, 80, 14, 14]             160\n",
            "      MBConvBlock-72           [-1, 80, 14, 14]               0\n",
            "Conv2dSamePadding-73          [-1, 480, 14, 14]          38,400\n",
            "      BatchNorm2d-74          [-1, 480, 14, 14]             960\n",
            "Conv2dSamePadding-75          [-1, 480, 14, 14]          12,000\n",
            "      BatchNorm2d-76          [-1, 480, 14, 14]             960\n",
            "Conv2dSamePadding-77             [-1, 20, 1, 1]           9,620\n",
            "Conv2dSamePadding-78            [-1, 480, 1, 1]          10,080\n",
            "Conv2dSamePadding-79          [-1, 112, 14, 14]          53,760\n",
            "      BatchNorm2d-80          [-1, 112, 14, 14]             224\n",
            "      MBConvBlock-81          [-1, 112, 14, 14]               0\n",
            "Conv2dSamePadding-82          [-1, 672, 14, 14]          75,264\n",
            "      BatchNorm2d-83          [-1, 672, 14, 14]           1,344\n",
            "Conv2dSamePadding-84          [-1, 672, 14, 14]          16,800\n",
            "      BatchNorm2d-85          [-1, 672, 14, 14]           1,344\n",
            "Conv2dSamePadding-86             [-1, 28, 1, 1]          18,844\n",
            "Conv2dSamePadding-87            [-1, 672, 1, 1]          19,488\n",
            "Conv2dSamePadding-88          [-1, 112, 14, 14]          75,264\n",
            "      BatchNorm2d-89          [-1, 112, 14, 14]             224\n",
            "      MBConvBlock-90          [-1, 112, 14, 14]               0\n",
            "Conv2dSamePadding-91          [-1, 672, 14, 14]          75,264\n",
            "      BatchNorm2d-92          [-1, 672, 14, 14]           1,344\n",
            "Conv2dSamePadding-93          [-1, 672, 14, 14]          16,800\n",
            "      BatchNorm2d-94          [-1, 672, 14, 14]           1,344\n",
            "Conv2dSamePadding-95             [-1, 28, 1, 1]          18,844\n",
            "Conv2dSamePadding-96            [-1, 672, 1, 1]          19,488\n",
            "Conv2dSamePadding-97          [-1, 112, 14, 14]          75,264\n",
            "      BatchNorm2d-98          [-1, 112, 14, 14]             224\n",
            "      MBConvBlock-99          [-1, 112, 14, 14]               0\n",
            "Conv2dSamePadding-100          [-1, 672, 14, 14]          75,264\n",
            "     BatchNorm2d-101          [-1, 672, 14, 14]           1,344\n",
            "Conv2dSamePadding-102            [-1, 672, 7, 7]          16,800\n",
            "     BatchNorm2d-103            [-1, 672, 7, 7]           1,344\n",
            "Conv2dSamePadding-104             [-1, 28, 1, 1]          18,844\n",
            "Conv2dSamePadding-105            [-1, 672, 1, 1]          19,488\n",
            "Conv2dSamePadding-106            [-1, 192, 7, 7]         129,024\n",
            "     BatchNorm2d-107            [-1, 192, 7, 7]             384\n",
            "     MBConvBlock-108            [-1, 192, 7, 7]               0\n",
            "Conv2dSamePadding-109           [-1, 1152, 7, 7]         221,184\n",
            "     BatchNorm2d-110           [-1, 1152, 7, 7]           2,304\n",
            "Conv2dSamePadding-111           [-1, 1152, 7, 7]          28,800\n",
            "     BatchNorm2d-112           [-1, 1152, 7, 7]           2,304\n",
            "Conv2dSamePadding-113             [-1, 48, 1, 1]          55,344\n",
            "Conv2dSamePadding-114           [-1, 1152, 1, 1]          56,448\n",
            "Conv2dSamePadding-115            [-1, 192, 7, 7]         221,184\n",
            "     BatchNorm2d-116            [-1, 192, 7, 7]             384\n",
            "     MBConvBlock-117            [-1, 192, 7, 7]               0\n",
            "Conv2dSamePadding-118           [-1, 1152, 7, 7]         221,184\n",
            "     BatchNorm2d-119           [-1, 1152, 7, 7]           2,304\n",
            "Conv2dSamePadding-120           [-1, 1152, 7, 7]          28,800\n",
            "     BatchNorm2d-121           [-1, 1152, 7, 7]           2,304\n",
            "Conv2dSamePadding-122             [-1, 48, 1, 1]          55,344\n",
            "Conv2dSamePadding-123           [-1, 1152, 1, 1]          56,448\n",
            "Conv2dSamePadding-124            [-1, 192, 7, 7]         221,184\n",
            "     BatchNorm2d-125            [-1, 192, 7, 7]             384\n",
            "     MBConvBlock-126            [-1, 192, 7, 7]               0\n",
            "Conv2dSamePadding-127           [-1, 1152, 7, 7]         221,184\n",
            "     BatchNorm2d-128           [-1, 1152, 7, 7]           2,304\n",
            "Conv2dSamePadding-129           [-1, 1152, 7, 7]          28,800\n",
            "     BatchNorm2d-130           [-1, 1152, 7, 7]           2,304\n",
            "Conv2dSamePadding-131             [-1, 48, 1, 1]          55,344\n",
            "Conv2dSamePadding-132           [-1, 1152, 1, 1]          56,448\n",
            "Conv2dSamePadding-133            [-1, 192, 7, 7]         221,184\n",
            "     BatchNorm2d-134            [-1, 192, 7, 7]             384\n",
            "     MBConvBlock-135            [-1, 192, 7, 7]               0\n",
            "Conv2dSamePadding-136           [-1, 1152, 7, 7]         221,184\n",
            "     BatchNorm2d-137           [-1, 1152, 7, 7]           2,304\n",
            "Conv2dSamePadding-138           [-1, 1152, 7, 7]          10,368\n",
            "     BatchNorm2d-139           [-1, 1152, 7, 7]           2,304\n",
            "Conv2dSamePadding-140             [-1, 48, 1, 1]          55,344\n",
            "Conv2dSamePadding-141           [-1, 1152, 1, 1]          56,448\n",
            "Conv2dSamePadding-142            [-1, 320, 7, 7]         368,640\n",
            "     BatchNorm2d-143            [-1, 320, 7, 7]             640\n",
            "     MBConvBlock-144            [-1, 320, 7, 7]               0\n",
            "Conv2dSamePadding-145           [-1, 1280, 7, 7]         409,600\n",
            "     BatchNorm2d-146           [-1, 1280, 7, 7]           2,560\n",
            "          Linear-147                   [-1, 10]          12,810\n",
            "================================================================\n",
            "Total params: 4,020,358\n",
            "Trainable params: 4,020,358\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 107.31\n",
            "Params size (MB): 15.34\n",
            "Estimated Total Size (MB): 123.22\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torchsummary\n",
        "from torchsummary import summary\n",
        "model = EfficientNet()\n",
        "summary(model,(3,224,224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "e5b38ae8e90b488fb6b1ed9f4b785f48",
            "699f7614202243139e5009c5e89b51b9",
            "4ec34848ae5a49da80e41bb8a0adba91",
            "22e5f8cafb2e433aa390944dcb447757",
            "b003577951754adf9eef8fe43182c6a4",
            "a71215a9700546ee808fb093af6df451",
            "728df072e01944ada9142c2814d6ca23",
            "92c186047f47435aa6405354e03035da",
            "bbf384d32b9a4a6ebfccff587abd398e",
            "0a611d97cfe041ce8cd6da849a3075ae",
            "35bfa27117a7497e8204be139cb2a6a6"
          ]
        },
        "id": "SbmNqz6wDlXY",
        "outputId": "a8a28e27-f8aa-4908-d8cb-1122f4f82bcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5b38ae8e90b488fb6b1ed9f4b785f48",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "valset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64,\n",
        "                                         shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bExzEZvnDqYb",
        "outputId": "eb265a1a-f700-4802-8430-cc9058d33b7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1/10 | batch: 100 | trn loss: 2.0605 | trn acc: 22.4375%\n",
            "epoch: 1/10 | batch: 200 | trn loss: 1.9110 | trn acc: 27.8906%\n",
            "epoch: 1/10 | batch: 300 | trn loss: 1.8011 | trn acc: 31.8073%\n",
            "epoch: 1/10 | batch: 400 | trn loss: 1.7139 | trn acc: 35.2188%\n",
            "epoch: 1/10 | batch: 500 | trn loss: 1.6368 | trn acc: 38.2969%\n"
          ]
        }
      ],
      "source": [
        "# loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# backpropagation method\n",
        "learning_rate = 1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "# hyper-parameters\n",
        "num_epochs = 10\n",
        "num_batches = len(trainloader)\n",
        "\n",
        "list_epoch = [] \n",
        "list_train_loss = []\n",
        "list_val_loss = []\n",
        "list_train_acc = []\n",
        "list_val_acc = []\n",
        "train_total = 0\n",
        "val_total= 0\n",
        "train_correct = 0\n",
        "val_correct = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    trn_loss = 0.0\n",
        "    train_total = 0\n",
        "    #val_total= 0\n",
        "    train_correct = 0\n",
        "    #val_correct = 0\n",
        "    for i, data in enumerate(trainloader):\n",
        "        x, labels = data\n",
        "        # grad init\n",
        "        optimizer.zero_grad()\n",
        "        # forward propagation\n",
        "        model_output = model(x)\n",
        "        # calculate acc\n",
        "        _, predicted = torch.max(model_output.data, 1)\n",
        "        train_total += labels.size(0)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "        # calculate loss\n",
        "        loss = criterion(model_output, labels)\n",
        "        # back propagation \n",
        "        loss.backward()\n",
        "        # weight update\n",
        "        optimizer.step()\n",
        "        \n",
        "        # trn_loss summary\n",
        "        trn_loss += loss.item()\n",
        "        # del (memory issue)\n",
        "        del loss\n",
        "        del model_output\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(\"epoch: {}/{} | batch: {} | trn loss: {:.4f} | trn acc: {:.4f}%\".\n",
        "                  format(epoch+1, num_epochs, i+1,  trn_loss / i, 100 * train_correct / train_total)) \n",
        "        \n",
        "        # # 학습과정 출력\n",
        "        # if (i+1) % 100 == 0: # every 100 mini-batches\n",
        "        #     with torch.no_grad(): # very very very very important!!!\n",
        "        #         val_loss = 0.0\n",
        "        #         for j, val in enumerate(valloader):\n",
        "        #             val_x, val_labels = val\n",
        "        #             val_output = model(val_x)\n",
        "        #             # calculate acc\n",
        "        #             _, predicted = torch.max(val_output.data, 1)\n",
        "        #             val_total += val_labels.size(0)\n",
        "        #             val_correct += (predicted == val_labels).sum().item()\n",
        "\n",
        "        #             v_loss = criterion(val_output, val_labels)\n",
        "        #             val_loss += v_loss\n",
        "                       \n",
        "        #     print(\"epoch: {}/{} | batch: {} | trn loss: {:.4f} | trn acc: {:.4f}% | val loss: {:.4f} | val acc: {:.4f}%\".\n",
        "        #           format(epoch+1, num_epochs, i+1,  trn_loss / i, 100 * train_correct / train_total, \n",
        "        #                  val_loss / len(valloader), 100 * val_correct / val_total))          \n",
        "    list_epoch.append(epoch+1)\n",
        "    list_train_loss.append(trn_loss/num_batches)\n",
        "    #list_val_loss.append(val_loss/len(valloader))\n",
        "    list_train_acc.append(100 * train_correct / train_total)\n",
        "    #list_val_acc.append(100 * val_correct / val_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaE9vcswDqfr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a611d97cfe041ce8cd6da849a3075ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22e5f8cafb2e433aa390944dcb447757": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a611d97cfe041ce8cd6da849a3075ae",
            "placeholder": "​",
            "style": "IPY_MODEL_35bfa27117a7497e8204be139cb2a6a6",
            "value": " 170498071/170498071 [00:13&lt;00:00, 15718911.35it/s]"
          }
        },
        "35bfa27117a7497e8204be139cb2a6a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ec34848ae5a49da80e41bb8a0adba91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92c186047f47435aa6405354e03035da",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbf384d32b9a4a6ebfccff587abd398e",
            "value": 170498071
          }
        },
        "699f7614202243139e5009c5e89b51b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a71215a9700546ee808fb093af6df451",
            "placeholder": "​",
            "style": "IPY_MODEL_728df072e01944ada9142c2814d6ca23",
            "value": "100%"
          }
        },
        "728df072e01944ada9142c2814d6ca23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92c186047f47435aa6405354e03035da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a71215a9700546ee808fb093af6df451": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b003577951754adf9eef8fe43182c6a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbf384d32b9a4a6ebfccff587abd398e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5b38ae8e90b488fb6b1ed9f4b785f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_699f7614202243139e5009c5e89b51b9",
              "IPY_MODEL_4ec34848ae5a49da80e41bb8a0adba91",
              "IPY_MODEL_22e5f8cafb2e433aa390944dcb447757"
            ],
            "layout": "IPY_MODEL_b003577951754adf9eef8fe43182c6a4"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}